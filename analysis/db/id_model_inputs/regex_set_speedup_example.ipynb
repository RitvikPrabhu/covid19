{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import nltk.data\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from pyprojroot import here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import  Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_term_to_regex(term):\n",
    "    words = term.split(\" \")\n",
    "    regex_pattern = \"\"\n",
    "    for term in words:\n",
    "        regex_pattern += f\"(?=.*\\\\b{term}\\\\b)\"\n",
    "    regex_pattern += \"\"\n",
    "    return regex_pattern\n",
    "assert convert_term_to_regex(\"incubation period\") == \"(?=.*\\\\bincubation\\\\b)(?=.*\\\\bperiod\\\\b)\"\n",
    "\n",
    "def find_matches_in_list(sentences, terms):\n",
    "    \"\"\"Determins if a term exists in a list of sentences\n",
    "    \"\"\"\n",
    "    matches = {}\n",
    "    for trm in terms:\n",
    "        pattern = convert_term_to_regex(trm)\n",
    "        for sent in sentences:\n",
    "            if (re.search(pattern, sent)):\n",
    "                matches[trm] = True\n",
    "                break # if there is a pattern match go to the next term\n",
    "    return(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv(here(\"./data/db/final/kaggle/paper_text/document_parses_pmc_json.tsv\"),\n",
    "                 sep='\\t', nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle') # nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = [\n",
    "    \"incubation period\",\n",
    "    \"infectiousness period\",\n",
    "    \"recovery rate\",\n",
    "    \"case fatality ratio\",\n",
    "    \"case fatality rate\",\n",
    "    \"asymptomatic fraction\",\n",
    "    \"asymptomatic proportion\",\n",
    "    \"asymptomatic ratio\",\n",
    "    \"hospitalized fraction\",\n",
    "    \"hospitalized proportion\",\n",
    "    \"latent period\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-540aa230f8fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_terms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'period of incubation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "bool(search_terms[0].search('period of incubation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danie\\miniconda3\\envs\\db_covid19\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Split sentences: 100%|█████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 57.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:00.199001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Split sentences\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "pdf[\"text_sent_lower\"] = pdf[\"text\"].progress_apply(lambda x: sent_detector.tokenize(x.lower().strip()))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:00.176000\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "pdf[\"text_sent_lower\"] = pdf[\"text\"].apply(lambda x: sent_detector.tokenize(x.lower().strip()))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding terms: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:15.261056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Finding terms\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "pdf['found_terms'] = pdf['text_sent_lower'].progress_apply(find_matches_in_list, terms=search_terms)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding terms: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-07 s\n",
       "\n",
       "Total time: 14.499 s\n",
       "File: <ipython-input-2-5844719b7f72>\n",
       "Function: find_matches_in_list at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                           def find_matches_in_list(sentences, terms):\n",
       "    11                                               \"\"\"Determins if a term exists in a list of sentences\n",
       "    12                                               \"\"\"\n",
       "    13        10        301.0     30.1      0.0      matches = {}\n",
       "    14       120       1653.0     13.8      0.0      for trm in terms:\n",
       "    15       110      17787.0    161.7      0.0          pattern = convert_term_to_regex(trm)\n",
       "    16     14846     284649.0     19.2      0.2          for sent in sentences:\n",
       "    17     14738  144685691.0   9817.2     99.8              if (re.search(pattern, sent)):\n",
       "    18         2         82.0     41.0      0.0                  matches[trm] = True\n",
       "    19         2         35.0     17.5      0.0                  break # if there is a pattern match go to the next term\n",
       "    20        10         80.0      8.0      0.0      return(matches)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f find_matches_in_list pdf[\"found_terms\"] = pdf[\"text_sent_lower\"].progress_apply(find_matches_in_list, terms=search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_sent_lower</th>\n",
       "      <th>found_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC1054884</td>\n",
       "      <td>7</td>\n",
       "      <td>Recombination Every Day: Abundant Recombinatio...</td>\n",
       "      <td>As increasing numbers of full-length viral seq...</td>\n",
       "      <td>[as increasing numbers of full-length viral se...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC1065028</td>\n",
       "      <td>1</td>\n",
       "      <td>Why can't I visit? The ethics of visitation re...</td>\n",
       "      <td>The sudden emergence of severe acute respirato...</td>\n",
       "      <td>[the sudden emergence of severe acute respirat...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC1065064</td>\n",
       "      <td>8</td>\n",
       "      <td>Prospective evaluation of an internet-linked h...</td>\n",
       "      <td>The rate of expansion of medical knowledge is ...</td>\n",
       "      <td>[the rate of expansion of medical knowledge is...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC1065120</td>\n",
       "      <td>4</td>\n",
       "      <td>Scanning the horizon: emerging hospital-wide t...</td>\n",
       "      <td>This series of articles provides regular surve...</td>\n",
       "      <td>[this series of articles provides regular surv...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC1065257</td>\n",
       "      <td>3</td>\n",
       "      <td>Characterization of the frameshift signal of E...</td>\n",
       "      <td>Programmed −1 ribosomal frameshifting (hereaft...</td>\n",
       "      <td>[programmed −1 ribosomal frameshifting (hereaf...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pid  num_authors                                              title  \\\n",
       "0  PMC1054884            7  Recombination Every Day: Abundant Recombinatio...   \n",
       "1  PMC1065028            1  Why can't I visit? The ethics of visitation re...   \n",
       "2  PMC1065064            8  Prospective evaluation of an internet-linked h...   \n",
       "3  PMC1065120            4  Scanning the horizon: emerging hospital-wide t...   \n",
       "4  PMC1065257            3  Characterization of the frameshift signal of E...   \n",
       "\n",
       "                                                text  \\\n",
       "0  As increasing numbers of full-length viral seq...   \n",
       "1  The sudden emergence of severe acute respirato...   \n",
       "2  The rate of expansion of medical knowledge is ...   \n",
       "3  This series of articles provides regular surve...   \n",
       "4  Programmed −1 ribosomal frameshifting (hereaft...   \n",
       "\n",
       "                                     text_sent_lower found_terms  \n",
       "0  [as increasing numbers of full-length viral se...          {}  \n",
       "1  [the sudden emergence of severe acute respirat...          {}  \n",
       "2  [the rate of expansion of medical knowledge is...          {}  \n",
       "3  [this series of articles provides regular surv...          {}  \n",
       "4  [programmed −1 ribosomal frameshifting (hereaf...          {}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_list_to_list_set_tokens(list_of_sentences):\n",
    "    return [set(word_tokenize(sent)) for sent in list_of_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:00.683998\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "pdf[\"sent_set\"] = pdf[\"text_sent_lower\"].apply(sent_list_to_list_set_tokens)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-07 s\n",
       "\n",
       "Total time: 1.03239 s\n",
       "File: <ipython-input-15-7fb67494139a>\n",
       "Function: sent_list_to_list_set_tokens at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "=============================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f sent_list_to_list_set_tokens pdf[\"sent_set\"] = pdf[\"text_sent_lower\"].apply(sent_list_to_list_set_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as increasing numbers of full-length viral sequences become available, recombinant or mosaic viruses are being recognized more frequently [1,2,3].'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.loc[0, 'text_sent_lower'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',',\n",
       " '.',\n",
       " '1,2,3',\n",
       " '[',\n",
       " ']',\n",
       " 'are',\n",
       " 'as',\n",
       " 'available',\n",
       " 'become',\n",
       " 'being',\n",
       " 'frequently',\n",
       " 'full-length',\n",
       " 'increasing',\n",
       " 'more',\n",
       " 'mosaic',\n",
       " 'numbers',\n",
       " 'of',\n",
       " 'or',\n",
       " 'recognized',\n",
       " 'recombinant',\n",
       " 'sequences',\n",
       " 'viral',\n",
       " 'viruses'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.loc[0, 'sent_set'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_set_in_list(sent_set, terms):\n",
    "    \"\"\"Determins if a term exists in a list of sentences\n",
    "    \"\"\"\n",
    "    matches = {}\n",
    "    for trm in terms:\n",
    "        trm_set = set(trm.split(\" \"))\n",
    "        for st in sent_set:\n",
    "            if (trm_set.issubset(st)):\n",
    "                matches[trm] = True\n",
    "                break # if there is a pattern match go to the next term\n",
    "    return(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dan', 'hello'},\n",
       " {'hello', 'you'},\n",
       " {'brown', 'fox', 'quick', 'the'},\n",
       " {'?', 'I', 'a', 'have', 'my', 'word'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = ['dan hello', 'hello you', 'the quick brown fox', 'my I have a word?']\n",
    "test_sent_set = [set(word_tokenize(sent)) for sent in test_sent]\n",
    "test_sent_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello dan': True, 'fox': True, 'word': True}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_set_in_list(test_sent_set,\n",
    "                  ['hello dan', 'fox', 'tom nook', 'word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding terms: 100%|██████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 163.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-07 s\n",
       "\n",
       "Total time: 0.033616 s\n",
       "File: <ipython-input-38-418cf8c122eb>\n",
       "Function: find_set_in_list at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def find_set_in_list(sent_set, terms):\n",
       "     2                                               \"\"\"Determins if a term exists in a list of sentences\n",
       "     3                                               \"\"\"\n",
       "     4        10        180.0     18.0      0.1      matches = {}\n",
       "     5       120       1206.0     10.1      0.4      for trm in terms:\n",
       "     6       110       3687.0     33.5      1.1          trm_set = set(trm.split(\" \"))\n",
       "     7     14867     130364.0      8.8     38.8          for st in sent_set:\n",
       "     8     14758     200608.0     13.6     59.7              if (trm_set.issubset(st)):\n",
       "     9         1         16.0     16.0      0.0                  matches[trm] = True\n",
       "    10         1          9.0      9.0      0.0                  break # if there is a pattern match go to the next term\n",
       "    11        10         90.0      9.0      0.0      return(matches)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f find_set_in_list pdf[\"found_terms\"] = pdf[\"sent_set\"].progress_apply(find_set_in_list, terms=search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chen', 'daniel'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find = set(['daniel', 'chen'])\n",
    "find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',', '.', ':', 'chen', 'daniel', 'hello', 'is', 'last', 'my', 'name'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = set(word_tokenize('hello, my name is daniel, last name: chen.'))\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.issubset(find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['daniel', 'chen'] in ['hello', 'my', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db_covid19",
   "language": "python",
   "name": "db_covid19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
