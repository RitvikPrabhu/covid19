I intend to use my knowledge of text analytics/NLP in R and Python in various manors. Most or hopefully all methods will be listed here. Firstly, I intend to clean the data quite heavily at first, removing punctuation, capitals, numeral, and stop words. I then hope to generate a list the most frequently used words and graph this using a stacked bar chart and wordclouds. Once I reached this point I also intend to preform TF-IDF (or: Term Frequency Inverse Document Frequency). I also hope to employ A Document Term Correlation Matrix, and hope to further explore the data in a more statistical/mathematical way once I've exausted all the methods previously mentioned. Finally, this is not an exhaustive list, thus, I am open to ideas on what direction I should go if Jon, Anne, or Daniel have any suggestions.